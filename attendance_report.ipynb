{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zlOM9pdv0EkC"
   },
   "outputs": [],
   "source": [
    "# !pip install gspread gspread-formatting gspread_dataframe oauth2client\n",
    "# !pip install gspread-formatting\n",
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "location = None\n",
    "print('>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>', location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2.service_account import Credentials\n",
    "import gspread\n",
    "import pandas as pd\n",
    "import gspread_dataframe\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NhaXwVTnfUwX"
   },
   "outputs": [],
   "source": [
    "# Load the configuration from the JSON file\n",
    "with open('config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Access values from the loaded config\n",
    "if  location not in ['blr', 'mum', 'pun']:\n",
    "    raise ValueError('Invalid Parameter')\n",
    "\n",
    "FOR_CURRENT_MONTH = config['FOR_CURRENT_MONTH']\n",
    "config = config[location]\n",
    "\n",
    "sheet_name = config['sheet_name']\n",
    "worksheet_name = config['worksheet_name']\n",
    "master_sheet_name = config['master_sheet_name']\n",
    "master_worksheet_name = config['master_worksheet_name']\n",
    "log_sheet_name = config['log_sheet_name']\n",
    "log_worksheet_name = config['log_worksheet_name']\n",
    "log_attendance_worksheet_name = config['log_attendance_worksheet_name']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdE6Jc-0YCB_"
   },
   "source": [
    "**Authorize Google Sheet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ySzJVFINRoYC",
    "outputId": "a60eda40-4925-4ee0-a7d9-d057f1c019e2"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZS7TGMEBMQey"
   },
   "outputs": [],
   "source": [
    "scopes= [\n",
    "    \"https://www.googleapis.com/auth/spreadsheets\",\n",
    "    \"https://www.googleapis.com/auth/drive\",\n",
    "    \"https://spreadsheets.google.com/feeds\"\n",
    "]\n",
    "\n",
    "# Authenticate google sheet with service account\n",
    "is_auth = Credentials.from_service_account_file('login_cred.json', scopes=scopes)\n",
    "gc = gspread.authorize(is_auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKvqnFAiYKMt"
   },
   "source": [
    "**Generate Log Report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "repwcWGcmsDF"
   },
   "outputs": [],
   "source": [
    "# Open google sheet\n",
    "sheet = gc.open(sheet_name)\n",
    "\n",
    "# Get worksheet\n",
    "worksheet = sheet.worksheet(worksheet_name)\n",
    "cols = ['Timestamp', 'Email Address', 'Full Name', 'Select your action']\n",
    "\n",
    "# Load sheet data into pandas dataframe with specific columns\n",
    "log_resp_df = gspread_dataframe.get_as_dataframe(worksheet=worksheet, usecols=cols)\n",
    "\n",
    "# Drop null rows\n",
    "log_resp_df.dropna(inplace=True, axis=0, how='all')\n",
    "\n",
    "# Typecast datetime column from str to datetime\n",
    "log_resp_df['Timestamp'] = pd.to_datetime(log_resp_df['Timestamp'])\n",
    "\n",
    "if FOR_CURRENT_MONTH:\n",
    "    current_month = datetime.now().month\n",
    "    current_year = datetime.now().year\n",
    "    # print(current_month, current_year)\n",
    "    log_resp_df = log_resp_df[(log_resp_df['Timestamp'].dt.month == current_month) & (log_resp_df['Timestamp'].dt.year == current_year)]\n",
    "# log_resp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "e4SHkiojl_Nr"
   },
   "outputs": [],
   "source": [
    "# Split DateTime and creates new columns as Date and Time in df\n",
    "log_resp_df[['Date', 'Time']] = log_resp_df['Timestamp'].apply(lambda x: pd.Series([x.date(), x.time()]))\n",
    "\n",
    "# Sort the values based on Date and Email\n",
    "sorted_log_resp_df = log_resp_df.sort_values(by=['Date', 'Email Address'])\n",
    "# sorted_log_resp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "4LKH-OtOte_P"
   },
   "outputs": [],
   "source": [
    "# Set Date and Email as index, pivots the datetime in two columns based on Action column\n",
    "final_log_df = sorted_log_resp_df.pivot_table(index=['Date', 'Email Address'],\n",
    "                                                 columns='Select your action',\n",
    "                                                 values='Timestamp',\n",
    "                                                 aggfunc='first')\n",
    "final_log_df.reset_index(inplace=True)\n",
    "\n",
    "# Typecast to datetime\n",
    "final_log_df['Login'] = pd.to_datetime(final_log_df['Login'])\n",
    "final_log_df['Logout'] = pd.to_datetime(final_log_df['Logout'])\n",
    "\n",
    "# to_hrs = lambda x: round(x.total_seconds() / 3600, 2) if pd.notnull(x) else pd.NaT\n",
    "final_log_df['TimeSpent'] = (final_log_df['Logout'] - final_log_df['Login'])\n",
    "# final_log_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GwQDxUSYRRo"
   },
   "source": [
    "**Open Master Sheet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "GKQrJ3ViYVQh"
   },
   "outputs": [],
   "source": [
    "# Open google sheet\n",
    "master_sheet = gc.open(master_sheet_name)\n",
    "\n",
    "# Get worksheet\n",
    "master_worksheet = master_sheet.worksheet(master_worksheet_name)\n",
    "\n",
    "data = master_worksheet.get_all_values()\n",
    "master_df = pd.DataFrame(data[1:], columns=data[0])\n",
    "# master_df\n",
    "\n",
    "# # Fetches only active candidates from master sheet\n",
    "cols = ['Admit ID', 'Name ', 'Email', 'Blr LabStatus']\n",
    "master_df = master_df[cols]\n",
    "master_df = master_df.rename(columns={'Name ': 'Name', 'Email': 'Email Address'})\n",
    "# master_df.dropna(inplace=True, axis=0, how='all')\n",
    "# master_df['Blr LabStatus'] = master_df['Blr LabStatus'].astype(str)\n",
    "master_df = master_df[master_df['Blr LabStatus'] == 'Active']\n",
    "# master_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bpilJcc3b94_"
   },
   "source": [
    "**Merge master and response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "tpfYhJ_ucDO9"
   },
   "outputs": [],
   "source": [
    "# Merge log response with master sheet based on active candidates\n",
    "merged_df = pd.merge(master_df, final_log_df, on='Email Address', how='inner')\n",
    "\n",
    "# Populate Date from Datetime\n",
    "merged_df['Date'] = pd.to_datetime(merged_df['Date']).apply(lambda x: x.date())\n",
    "\n",
    "# Convert timestamp to hours\n",
    "to_hrs = lambda x: round(x.total_seconds() / 3600, 2) if pd.notnull(x) else pd.NaT\n",
    "merged_df['TimeSpent'] = merged_df['TimeSpent'].apply(to_hrs)\n",
    "\n",
    "# Sort values based on log response date\n",
    "merged_df.sort_values(by=['Date'], inplace=True)\n",
    "# merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VxZviUqnoaKg",
    "outputId": "202c328e-ec61-4951-ee64-75278abaf318"
   },
   "outputs": [],
   "source": [
    "log_sheet = gc.open(log_sheet_name)\n",
    "\n",
    "# Get or create Dataframe in log csv file\n",
    "cols = ['Logged At', 'Log Date', \"Status\"]\n",
    "try:\n",
    "    log_worksheet = log_sheet.worksheet(log_worksheet_name)\n",
    "    date_log_df = gspread_dataframe.get_as_dataframe(log_worksheet, usecols=cols)\n",
    "    date_log_df.dropna(inplace=True, axis=0, how='all')\n",
    "except gspread.exceptions.WorksheetNotFound:\n",
    "    log_worksheet = log_sheet.add_worksheet(title=log_worksheet_name, rows=50, cols=20)\n",
    "    date_log_df = pd.DataFrame(columns=cols)\n",
    "except pd.errors.EmptyDataError:\n",
    "    date_log_df = pd.DataFrame()\n",
    "except ValueError:\n",
    "    date_log_df = pd.DataFrame(columns=cols)\n",
    "# date_log_df\n",
    "\n",
    "# Fetch unique dates from df\n",
    "days = merged_df['Date'].unique()\n",
    "\n",
    "# Fetch existing logged dates from csv file\n",
    "if not date_log_df.empty:\n",
    "    existing_dates = pd.to_datetime(date_log_df['Log Date'].unique()).date\n",
    "else:\n",
    "    existing_dates = np.array([])\n",
    "\n",
    "# Get dates to be added to master sheet\n",
    "new_dates = np.setdiff1d(days, existing_dates)\n",
    "\n",
    "if not FOR_CURRENT_MONTH:\n",
    "    today = pd.Timestamp.today()\n",
    "    start_of_current_month = today.replace(day=1).date()\n",
    "    start_of_previous_month = (start_of_current_month - pd.DateOffset(months=1)).replace(day=1).date()\n",
    "    new_dates = [date for date in new_dates if date >= start_of_previous_month]\n",
    "\n",
    "# new_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "iMDn4xtfODX_"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    attendance_sheet = log_sheet.worksheet(title=log_attendance_worksheet_name)\n",
    "    attendance_df = gspread_dataframe.get_as_dataframe(attendance_sheet)\n",
    "    attendance_df = attendance_df.loc[:, ~attendance_df.columns.str.contains('^Unnamed')]\n",
    "    attendance_df.columns = attendance_df.columns.str.replace(r'\\.\\d+$', '', regex=True)\n",
    "    attendance_df.columns = pd.MultiIndex.from_arrays([attendance_df.columns, attendance_df.iloc[0].fillna('')])\n",
    "    attendance_df.drop(0, inplace=True)\n",
    "\n",
    "except gspread.exceptions.WorksheetNotFound:\n",
    "    today = datetime.today()\n",
    "    year = today.year\n",
    "    month = today.month\n",
    "\n",
    "    no_of_days = calendar.monthrange(year, month)[1]\n",
    "    attendance_sheet = log_sheet.add_worksheet(title=log_attendance_worksheet_name, rows=100, cols=100)\n",
    "\n",
    "    attendance_df = master_df.copy()\n",
    "    attendance_df.columns = pd.MultiIndex.from_tuples(zip(attendance_df.columns, [''] * len(attendance_df.columns)))\n",
    "\n",
    "    # for i in range(1, no_of_days+1):\n",
    "    #     date_col = datetime(year, month, i).strftime('%Y-%m-%d')\n",
    "    #     attendance_df[(date_col, 'Status')] = np.nan\n",
    "    #     attendance_df[(date_col, 'Remarks')] = np.nan\n",
    "\n",
    "    gspread_dataframe.set_with_dataframe(attendance_sheet, attendance_df)\n",
    "\n",
    "# attendance_df.dropna(inplace=True, axis=1, how='all')\n",
    "attendance_df.dropna(inplace=True, axis=0, how='all')\n",
    "# attendance_df\n",
    "\n",
    "def determine_status_remarks(row):\n",
    "    login_is_valid = pd.notna(row['Login']) and row['Login'] != \"\"\n",
    "    logout_is_valid = pd.notna(row['Logout']) and row['Logout'] != \"\"\n",
    "\n",
    "    if login_is_valid and logout_is_valid:\n",
    "        status = 'P'\n",
    "        remarks = 'All good'\n",
    "    elif login_is_valid and not logout_is_valid:\n",
    "        status = 'P'\n",
    "        remarks = 'Logout not done'\n",
    "    elif not login_is_valid and logout_is_valid:\n",
    "        status = 'P'\n",
    "        remarks = 'Login not done'\n",
    "    else:\n",
    "        status = 'A'\n",
    "        remarks = 'Absent'\n",
    "\n",
    "    return pd.Series([status, remarks])\n",
    "\n",
    "status_df = merged_df.apply(determine_status_remarks, axis=1)\n",
    "status_df.columns = ['Status', 'Remarks']\n",
    "status_df = pd.concat([merged_df, status_df], axis=1)\n",
    "# merged_df\n",
    "pivot_df = status_df.pivot(index='Admit ID', columns='Date', values=['Status', 'Remarks'])\n",
    "pivot_df = pivot_df.swaplevel(0, 1, axis=1).sort_index(axis=1, level=0)\n",
    "pivot_df = pivot_df[[col for date in pivot_df.columns.levels[0] for col in [(date, 'Status'), (date, 'Remarks')]]]\n",
    "\n",
    "pivot_df = pivot_df[new_dates]\n",
    "\n",
    "attendance_df = attendance_df.merge(pivot_df, left_on='Admit ID', right_index=True, how='left')\n",
    "\n",
    "for date in new_dates:\n",
    "    attendance_df[(date, 'Status')] = attendance_df[(date, 'Status')].fillna('A')\n",
    "    attendance_df[(date, 'Remarks')] = attendance_df[(date, 'Remarks')].fillna('Absent')\n",
    "\n",
    "gspread_dataframe.set_with_dataframe(attendance_sheet, attendance_df)\n",
    "# attendance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "MRB_uvaEiwqK"
   },
   "outputs": [],
   "source": [
    "# Add new dates to master sheet\n",
    "dates_lst = []\n",
    "for date in new_dates:\n",
    "    time.sleep(1)\n",
    "    log_dict = {\"Logged At\": pd.Timestamp.now(tz='Asia/Kolkata'), \"Log Date\": date, \"Status\": \"Success\"}\n",
    "\n",
    "    formated_date = date.strftime('%d-%b-%Y') # 01-Jan-2024\n",
    "\n",
    "    # Get or create worksheet\n",
    "    try:\n",
    "        ws = log_sheet.worksheet(title=str(formated_date))\n",
    "    except gspread.exceptions.WorksheetNotFound:\n",
    "        ws = log_sheet.add_worksheet(title=str(formated_date), rows=100, cols=10)\n",
    "\n",
    "    # Clear and populate new data to worksheet\n",
    "    try:\n",
    "        ws.clear()\n",
    "        df = merged_df[merged_df['Date'] == date]\n",
    "        # print(df)\n",
    "        gspread_dataframe.set_with_dataframe(ws, df)\n",
    "    except gspread.exceptions.APIError:\n",
    "        log_dict['Status'] = \"Failed\"\n",
    "\n",
    "    dates_lst.append(log_dict)\n",
    "\n",
    "# Log the latest dates added to csv file\n",
    "date_log_df = pd.concat([date_log_df, pd.DataFrame(dates_lst)])\n",
    "gspread_dataframe.set_with_dataframe(log_worksheet, date_log_df)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "attendance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
